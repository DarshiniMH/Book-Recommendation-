{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DarshiniMH/Book-Recommendation-/blob/main/book_rec_User_Item.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r9tsuc5kfith",
        "outputId": "2792e094-7176-4c71-a633-fb6d856a7a13"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "egeaxsFk3-X6",
        "outputId": "57994d2c-71eb-4567-f988-3cc871c24153"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting rapidfuzz\n",
            "  Downloading rapidfuzz-3.12.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
            "Downloading rapidfuzz-3.12.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/3.1 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m93.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m55.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: rapidfuzz\n",
            "Successfully installed rapidfuzz-3.12.1\n"
          ]
        }
      ],
      "source": [
        "!pip install rapidfuzz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mu5WxsnigHii",
        "outputId": "f5cf05f5-c64c-4363-bd17-fafbde2d80e4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            " Top Book Matches:\n",
            "📖 The Alchemist (Book ID: 865, Ratings: 1342863, Avg Rating: 3.8200000000000003)\n",
            "📖 The Neutronium Alchemist (Night's Dawn, #2) (Book ID: 479561, Ratings: 12946, Avg Rating: 4.25)\n",
            "📖 The Alchemist (Book ID: 25076674, Ratings: 12171, Avg Rating: 3.8200000000000003)\n",
            "📖 The Alchemist (Book ID: 6071573, Ratings: 8174, Avg Rating: 3.8200000000000003)\n",
            "📖 The Alchemist (Book ID: 18144590, Ratings: 4908, Avg Rating: 3.8200000000000003)\n"
          ]
        }
      ],
      "source": [
        "import sqlite3\n",
        "import pandas as pd\n",
        "from rapidfuzz import process  # Alternative fuzzy matching in Python\n",
        "\n",
        "\n",
        "def search_books(title_query, conn, top_n=5):\n",
        "    \"\"\"\n",
        "    Search for a book title using FTS5 + fuzzy matching for typos.\n",
        "\n",
        "    Args:\n",
        "    - title_query (str): The user-provided book title.\n",
        "    - conn (sqlite3.Connection): The database connection.\n",
        "    - top_n (int): Number of results to return.\n",
        "\n",
        "    Returns:\n",
        "    - List of matched book details (book_id, title, ratings_count, average_rating).\n",
        "    \"\"\"\n",
        "    cursor = conn.cursor()\n",
        "\n",
        "    #  1. Direct FTS5 search (fastest)\n",
        "    query = f\"\"\"\n",
        "        SELECT b.book_id, b.title, b.ratings_count, b.average_rating\n",
        "        FROM books_fts fts\n",
        "        JOIN books b ON b.rowid = fts.rowid\n",
        "        WHERE books_fts MATCH ?\n",
        "        ORDER BY b.ratings_count DESC\n",
        "        LIMIT ?;\n",
        "    \"\"\"\n",
        "    cursor.execute(query, (title_query, top_n))\n",
        "    results = cursor.fetchall()\n",
        "\n",
        "    #  2. If no results, apply fuzzy matching using Python's `rapidfuzz`\n",
        "    if not results:\n",
        "        print(\"No exact matches found. Trying fuzzy matching...\")\n",
        "\n",
        "        # Fetch all book titles from the database\n",
        "        cursor.execute(\"SELECT title FROM books;\")\n",
        "        all_titles = [row[0] for row in cursor.fetchall()]\n",
        "\n",
        "        # Use `process.extract` to get the best fuzzy matches\n",
        "        fuzzy_matches = process.extract(title_query, all_titles, limit=top_n)\n",
        "\n",
        "        # Get the book details for matched titles\n",
        "        matched_titles = [match[0] for match in fuzzy_matches]\n",
        "        query = f\"\"\"\n",
        "            SELECT book_id, title, ratings_count, average_rating\n",
        "            FROM books\n",
        "            WHERE title IN ({','.join(['?']*len(matched_titles))})\n",
        "            ORDER BY ratings_count DESC\n",
        "            LIMIT ?;\n",
        "        \"\"\"\n",
        "        cursor.execute(query, (*matched_titles, top_n))\n",
        "        results = cursor.fetchall()\n",
        "\n",
        "    return results\n",
        "\n",
        "# Example Usage\n",
        "conn = sqlite3.connect(\"/content/drive/MyDrive/Book Recommendation/goodreads_books.db\")\n",
        "search_title = \"The alchemist\"  # Example with a typo\n",
        "matched_books = search_books(search_title, conn)\n",
        "\n",
        "# Display Results\n",
        "if matched_books:\n",
        "    print(\"\\n Top Book Matches:\")\n",
        "    for book in matched_books:\n",
        "        print(f\"📖 {book[1]} (Book ID: {book[0]}, Ratings: {book[2]}, Avg Rating: {book[3]})\")\n",
        "else:\n",
        "    print(\" No matches found!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9PLJQGfr8ksj",
        "outputId": "b7e1d0fb-df92-4f27-ca83-aaaaaa21a8f5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting faiss-cpu\n",
            "  Downloading faiss_cpu-1.10.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (4.4 kB)\n",
            "Requirement already satisfied: numpy<3.0,>=1.25.0 in /usr/local/lib/python3.11/dist-packages (from faiss-cpu) (1.26.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from faiss-cpu) (24.2)\n",
            "Downloading faiss_cpu-1.10.0-cp311-cp311-manylinux_2_28_x86_64.whl (30.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m30.7/30.7 MB\u001b[0m \u001b[31m288.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: faiss-cpu\n",
            "Successfully installed faiss-cpu-1.10.0\n"
          ]
        }
      ],
      "source": [
        "!pip install faiss-cpu --no-cache-dir\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ra2J89HEFVH0",
        "outputId": "dae28799-fe93-4154-8d47-a9b8e282b771"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset after cleaning: (63755324, 3)\n"
          ]
        }
      ],
      "source": [
        "import sqlite3\n",
        "import pandas as pd\n",
        "\n",
        "# Connect to the cleaned database\n",
        "conn = sqlite3.connect(\"/content/drive/MyDrive/Book Recommendation/goodreads_interactions_cleaned.db\")\n",
        "\n",
        "# Load the cleaned dataset\n",
        "query = \"SELECT user_id, book_id, rating FROM interactions WHERE rating >= 4\"\n",
        "df = pd.read_sql(query, conn)\n",
        "conn.close()\n",
        "\n",
        "print(f\"Dataset after cleaning: {df.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fMLdk7o4s-zi",
        "outputId": "6cabdb3b-f430-48ef-ae51-b71dfb4ce3e8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset after cleaning: (63125193, 3)\n"
          ]
        }
      ],
      "source": [
        "import sqlite3\n",
        "import pandas as pd\n",
        "\n",
        "# Connect to the cleaned database\n",
        "conn = sqlite3.connect(\"/content/drive/MyDrive/Book Recommendation/goodreads_interactions.db\")\n",
        "\n",
        "# Load the cleaned dataset\n",
        "query = \"SELECT user_id, book_id, rating FROM interactions_filtered WHERE rating >= 4\"\n",
        "df = pd.read_sql(query, conn)\n",
        "conn.close()\n",
        "\n",
        "print(f\"Dataset after cleaning: {df.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g7Eo1m5o29YB",
        "outputId": "d1f4455c-1ad1-488d-d747-b9c5cb2ebd11"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[['user_id', 'INTEGER'], ['book_id', 'INTEGER'], ['rating', 'INTEGER'], ['is_read', 'INTEGER'], ['is_reviewed', 'INTEGER']]\n"
          ]
        }
      ],
      "source": [
        "import sqlite3\n",
        "import pandas as pd\n",
        "\n",
        "# ✅ Connect to SQLite database\n",
        "db_path = \"/content/drive/MyDrive/Book Recommendation/goodreads_interactions_cleaned.db\"  # Update with your correct path\n",
        "conn = sqlite3.connect(db_path)\n",
        "cursor = conn.cursor()\n",
        "\n",
        "\n",
        "# ✅ Step 2: Fetch Column Names of `interactions` Table\n",
        "cursor.execute(\"PRAGMA table_info(interactions);\")\n",
        "columns_info = cursor.fetchall()\n",
        "\n",
        "# ✅ Extract column names\n",
        "column_names = [[column[1],column[2]] for column in columns_info]\n",
        "print(column_names)\n",
        "\n",
        "# ✅ Close connection\n",
        "conn.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7WFtB0I88YAk"
      },
      "outputs": [],
      "source": [
        "import sqlite3\n",
        "import pandas as pd\n",
        "from scipy.sparse import coo_matrix\n",
        "import numpy as np\n",
        "import faiss\n",
        "import os\n",
        "\n",
        "# Define chunk size\n",
        "chunk_size = 500000\n",
        "\n",
        "#  Connect to the SQLite database (Ensure `book_id` is an INTEGER)\n",
        "conn = sqlite3.connect(\"/content/drive/MyDrive/Book Recommendation/goodreads_interactions.db\")\n",
        "\n",
        "#  Create empty lists to store chunks\n",
        "user_indices = []\n",
        "book_indices = []\n",
        "ratings = []\n",
        "\n",
        "#  Read data in chunks\n",
        "query = \"SELECT user_id, book_id, rating FROM interactions_filtered WHERE rating > 3\"\n",
        "chunks = pd.read_sql_query(query, conn, chunksize=chunk_size)\n",
        "\n",
        "for chunk in chunks:\n",
        "    # Ensure `book_id` and `user_id` remain INTEGER\n",
        "    chunk[\"user_index\"] = chunk[\"user_id\"].astype(\"category\").cat.codes\n",
        "    chunk[\"book_index\"] = chunk[\"book_id\"].astype(\"category\").cat.codes\n",
        "    chunk[\"rating\"] = pd.to_numeric(chunk[\"rating\"], downcast=\"integer\")\n",
        "\n",
        "    # Store chunk data in lists\n",
        "    user_indices.extend(chunk[\"user_index\"].tolist())\n",
        "    book_indices.extend(chunk[\"book_index\"].tolist())\n",
        "    ratings.extend(chunk[\"rating\"].tolist())\n",
        "\n",
        "#  Close database connection\n",
        "conn.close()\n",
        "\n",
        "#  Create a sparse book-user interaction matrix\n",
        "book_user_matrix = coo_matrix((ratings, (book_indices, user_indices))).tocsr()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "MVpdQi3N3SCY",
        "outputId": "67b13bce-82c2-492a-cc3d-eb198be86803"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Original dimensionality: 8202\n",
            "Explained variance with 1000 components: 63.56%\n",
            "Reduced dimensionality: 1001\n"
          ]
        }
      ],
      "source": [
        "#  Perform Dimensionality Reduction (Truncated SVD)\n",
        "from sklearn.decomposition import TruncatedSVD\n",
        "\n",
        "n_books, n_users = book_user_matrix.shape\n",
        "print(\"Original dimensionality:\", n_users)\n",
        "\n",
        "# Retain 98% variance\n",
        "target_variance = 0.98\n",
        "svd = TruncatedSVD(n_components=min(n_users,1000), random_state=42)\n",
        "reduced_matrix = svd.fit_transform(book_user_matrix)\n",
        "explained = svd.explained_variance_ratio_.sum()\n",
        "print(f\"Explained variance with {min(n_users,1000)} components: {explained*100:.2f}%\")\n",
        "\n",
        "\n",
        "#  Find optimal number of dimensions\n",
        "cumulative_variance = np.cumsum(svd.explained_variance_ratio_)\n",
        "optimal_d = np.searchsorted(cumulative_variance, target_variance) + 1\n",
        "reduced_vectors = reduced_matrix[:, :optimal_d].astype(\"float32\")\n",
        "print(f\"Reduced dimensionality: {optimal_d}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n4MjjDSB3qnv"
      },
      "outputs": [],
      "source": [
        "#  Normalize vectors for cosine similarity\n",
        "def normalize_vectors(vectors):\n",
        "    norms = np.linalg.norm(vectors, axis=1, keepdims=True)\n",
        "    return vectors / norms\n",
        "\n",
        "reduced_vectors = normalize_vectors(reduced_vectors)\n",
        "\n",
        "#  Create FAISS Index for Fast Similarity Search\n",
        "nlist = 4096  # Number of Voronoi clusters\n",
        "m = 16        # PQ sub-quantizers\n",
        "nbits = 8     # Bits per sub-vector\n",
        "optimal_d = int((optimal_d // m) * m)  # Round down to nearest multiple of m\n",
        "\n",
        "reduced_vectors = reduced_vectors[:, :optimal_d]\n",
        "\n",
        "#  Use FAISS Index for Cosine Similarity\n",
        "quantizer = faiss.IndexFlatIP(optimal_d)\n",
        "index = faiss.IndexIVFPQ(quantizer, optimal_d, nlist, m, nbits)\n",
        "print(\"Cosine similarity index created with dimension\", optimal_d)\n",
        "\n",
        "#  Train FAISS index\n",
        "sample_size = min(100000, n_books)\n",
        "train_data = reduced_vectors[np.random.choice(n_books, sample_size, replace=False)]\n",
        "index.train(train_data)\n",
        "print(\"Index trained on sample of size:\", sample_size)\n",
        "\n",
        "#  Add vectors to FAISS in batches\n",
        "batch_size = 50000\n",
        "for i in range(0, n_books, batch_size):\n",
        "    end = min(i + batch_size, n_books)\n",
        "    index.add(reduced_vectors[i:end])\n",
        "    print(f\"Added vectors {i} to {end}\")\n",
        "\n",
        "print(\"Total indexed vectors:\", index.ntotal)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bf1ajxH-339I"
      },
      "outputs": [],
      "source": [
        "#  Save FAISS index to disk\n",
        "faiss.write_index(index, \"/content/drive/MyDrive/Book Recommendation/books_index.faiss\")\n",
        "print(\"Index saved to books_index.faiss (size: %.2f MB)\" % (os.path.getsize(\"/content/drive/MyDrive/Book Recommendation/books_index.faiss\") / 1024**2))\n",
        "\n",
        "#  Load FAISS index for querying\n",
        "index = faiss.read_index(\"/content/drive/MyDrive/Book Recommendation/books_index.faiss\")\n",
        "index.nprobe = 10\n",
        "print(\"Index loaded. Total vectors:\", index.ntotal)\n",
        "\n",
        "# 3.3 Example query: find top-5 similar books for a given book vector (or user vector)\n",
        "query_vec = reduced_vectors[0]  # e.g., first book's vector as a query\n",
        "D, I = index.search(query_vec.reshape(1, -1), k=5)\n",
        "print(\"Recommended book IDs for the query:\", I[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 160
        },
        "id": "LWVjbKYg8b-O",
        "outputId": "2b9d71e8-9455-43ce-9cdc-7d2a6cd3fd68"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\n# ✅ Example: Get recommendations for a book\\nbook_id_to_query = 5470  # Replace with a real book_id from your dataset\\nbook_mapping = {book_id: idx for idx, book_id in enumerate(pd.read_sql(\"SELECT book_id FROM books\", sqlite3.connect(\"/content/drive/MyDrive/Book Recommendation/goodreads_books.db\"))[\"book_id\"])}\\nrecommended_books = get_recommendations(book_id_to_query, book_mapping, reduced_vectors, index, k=5)\\n\\n# ✅ Display Results\\nif recommended_books:\\n    print(\"\\n📚 Top 5 Recommended Books:\")\\n    for book in recommended_books:\\n        print(f\"📖 {book[1]} (Book ID: {book[0]}, Avg Rating: {book[2]})\")\\nelse:\\n    print(\"❌ No recommendations found!\")\\n    '"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def get_recommendations(book_id, book_mapping, reduced_vectors, index, k=5):\n",
        "    \"\"\"\n",
        "    Get top-k similar books for a given book_id.\n",
        "\n",
        "    Args:\n",
        "    - book_id (int): The book_id from the dataset.\n",
        "    - book_mapping (dict): Mapping from book_id to book_index.\n",
        "    - reduced_vectors (numpy array): The book embedding matrix.\n",
        "    - index (faiss index): The trained FAISS index.\n",
        "    - k (int): Number of recommendations to retrieve.\n",
        "\n",
        "    Returns:\n",
        "    - recommended_books (list): List of recommended books with their details.\n",
        "    \"\"\"\n",
        "    conn = sqlite3.connect(\"/content/drive/MyDrive/Book Recommendation/goodreads_books.db\")\n",
        "    cursor = conn.cursor()\n",
        "\n",
        "    # ✅ Step 1: Ensure book_id is valid\n",
        "    if book_id not in book_mapping:\n",
        "        print(f\"Error: Book ID {book_id} not found in mapping.\")\n",
        "        return []\n",
        "\n",
        "    book_index = book_mapping[book_id]\n",
        "\n",
        "    # ✅ Step 2: Retrieve book vector\n",
        "    query_vec = reduced_vectors[book_index].reshape(1, -1)\n",
        "\n",
        "    # ✅ Step 3: Perform FAISS search\n",
        "    D, I = index.search(query_vec, k+1)\n",
        "\n",
        "    # ✅ Step 4: Convert book indices back to book_ids\n",
        "    recommended_book_ids = [key for key, val in book_mapping.items() if val in I[0] and val != book_index]\n",
        "\n",
        "    # ✅ Step 5: Fetch book details from `goodreads_books.db`\n",
        "    placeholders = \",\".join([\"?\"] * len(recommended_book_ids))\n",
        "    query = f\"SELECT book_id, title, average_rating FROM books WHERE book_id IN ({placeholders}) ORDER BY average_rating DESC\"\n",
        "    cursor.execute(query, recommended_book_ids)\n",
        "    recommended_books = cursor.fetchall()\n",
        "\n",
        "    conn.close()\n",
        "\n",
        "    return recommended_books\n",
        "\"\"\"\n",
        "# ✅ Example: Get recommendations for a book\n",
        "book_id_to_query = 5470  # Replace with a real book_id from your dataset\n",
        "book_mapping = {book_id: idx for idx, book_id in enumerate(pd.read_sql(\"SELECT book_id FROM books\", sqlite3.connect(\"/content/drive/MyDrive/Book Recommendation/goodreads_books.db\"))[\"book_id\"])}\n",
        "recommended_books = get_recommendations(book_id_to_query, book_mapping, reduced_vectors, index, k=5)\n",
        "\n",
        "# ✅ Display Results\n",
        "if recommended_books:\n",
        "    print(\"\\n📚 Top 5 Recommended Books:\")\n",
        "    for book in recommended_books:\n",
        "        print(f\"📖 {book[1]} (Book ID: {book[0]}, Avg Rating: {book[2]})\")\n",
        "else:\n",
        "    print(\"❌ No recommendations found!\")\n",
        "    \"\"\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WeNKm3eFCk0Q",
        "outputId": "1736eb31-0d46-4f77-f245-e68ffe78619a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "📖 Selected Book for Recommendation: The Alchemist (Book ID: 865)\n",
            "\n",
            "📚 Recommended Books:\n",
            "📖 J.R.R. Tolkien 4-Book Boxed Set: The Hobbit and The Lord of the Rings (Book ID: 30, Avg Rating: 4.59)\n",
            "📖 Harry Potter and the Half-Blood Prince (Harry Potter, #6) (Book ID: 1, Avg Rating: 4.54)\n",
            "📖 The Lord of the Rings (The Lord of the Rings, #1-3) (Book ID: 32, Avg Rating: 4.48)\n",
            "📖 Harry Potter and the Sorcerer's Stone (Harry Potter, #1) (Book ID: 3, Avg Rating: 4.45)\n",
            "📖 The Mother Tongue: English and How It Got That Way (Book ID: 29, Avg Rating: 3.95)\n"
          ]
        }
      ],
      "source": [
        "# ✅ Connect to the books database\n",
        "conn = sqlite3.connect(\"/content/drive/MyDrive/Book Recommendation/goodreads_books.db\")\n",
        "\n",
        "# ✅ Step 1: Search for the book by title\n",
        "search_title = \"The alchemist\"  # Example search query\n",
        "matched_books = search_books(search_title, conn)  # Calls the search function\n",
        "\n",
        "# ✅ Step 2: Get the first book_id from the search results\n",
        "if matched_books:\n",
        "    first_book_id = matched_books[0][0]  # Extract the book_id of the first match\n",
        "\n",
        "    print(f\"\\n📖 Selected Book for Recommendation: {matched_books[0][1]} (Book ID: {first_book_id})\")\n",
        "\n",
        "    # ✅ Step 3: Load the book_id → book_index mapping\n",
        "    book_mapping_conn = sqlite3.connect(\"/content/drive/MyDrive/Book Recommendation/goodreads_books.db\")\n",
        "    book_mapping_query = \"SELECT book_id FROM books\"\n",
        "    book_mapping_df = pd.read_sql(book_mapping_query, book_mapping_conn)\n",
        "    book_mapping = {book_id: idx for idx, book_id in enumerate(book_mapping_df[\"book_id\"])}\n",
        "\n",
        "    # ✅ Step 4: Call get_recommendations() with the retrieved book_id\n",
        "    recommended_books = get_recommendations(first_book_id, book_mapping, reduced_vectors, index, k=5)\n",
        "\n",
        "    # ✅ Step 5: Display the recommended books\n",
        "    if recommended_books:\n",
        "        print(\"\\n📚 Recommended Books:\")\n",
        "        for book in recommended_books:\n",
        "            print(f\"📖 {book[1]} (Book ID: {book[0]}, Avg Rating: {book[2]})\")\n",
        "    else:\n",
        "        print(\"❌ No recommendations found!\")\n",
        "else:\n",
        "    print(\"❌ No matches found for the given book title!\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "authorship_tag": "ABX9TyO/1R6maUAw32mhNfq9spct",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}